---
title: "Day 2"
output:
  html_document:
    df_print: paged
---

```{r}
library(forecast)
library(ggplot2)
library(tseries)
```

### EXERCISE 1 : AIRPASSENGERS

1.  **Plot of the time serie**

```{r}
plot (AirPassengers)
ggseasonplot (AirPassengers)
```

The data are seasonal and have an increasing trend.

2.  **Data decomposition :**

```{r}
autoplot(decompose(AirPassengers,type="additive"))+xlab('Year')
```

3.  **Differenciation :**

-   Use diff() function with lag=12, because values are monthly and the season period is one year (data are correlated from one month to the same month next year). Result is not enough. We can see that values are still correlated looking at the ACF plot. This is confirmed by the Dickey-Fuller test (p-value \> 0.05).

-   As result is not enough, we apply again the diff() function, this time with lag=1 (default value). We obtain a plot which is stationary (no trend and no seasonality). This is confirmed with the ACF plot where there is not trend. This also can be confirmed by the Dickey-Fuller test (p-value \< 0.05).

-   We use a box test to get the p-value of the last data. As the p-value is lower than 0.05 then it's proved that the data is not white noise and so we can continue the analyze. By default we use value of 10 for the lag.

```{r}
par(mfrow=c(3,1))
tsdisplay(AirPassengers)

tsdisplay(diff(AirPassengers,lag=12))
adf.test(diff(AirPassengers,lag=12))

tsdisplay(diff(diff(AirPassengers,lag=12)))
adf.test(diff(diff(AirPassengers,lag=12)))

Box.test(diff(diff(AirPassengers,lag=10)))
```

### EXERCISE 2 : USCHANGE

1.  **Install and load libraries**

```{r}
#install.packages('fpp2', dependencies = TRUE)
library(fpp2)
```

2.  **Plot the dataset USCHANGE**

```{r}
autoplot(uschange[,c("Income","Unemployment")]) + ylab("Values")
```

3.  **Choose the best ARIMA model**

[3.1 Data Analyse]{.ul}

```{r}
tsdisplay(uschange[,"Income"])
tsdisplay(uschange[,"Unemployment"])
Box.test(diff(uschange[,"Unemployment"]))
```

The Income data is stationary and the ACF shows that there is no correlation between the values (everything is below the blue line). It's impossible to forecast this data as information is independent.

The Unemployment data looks also stationary. However ACF shows there is a correlation. The boxtest show a very low p_value which means that there is no white noise and so we may forecast.

So for the rest of the exercise we will use only Unemployment data as we cannot forecast Income.

[3.2 Automatic guess]{.ul}

```{r}
auto.arima(uschange[,"Unemployment"])
```

The auto ARIMA guess that the best model is ARIMA(2,0,0).

[3.2 Manual guess]{.ul}

What do we learn with the ACF and PACF plotting ?

-   PACF : The last value which cross the blue line is Lag=8 so we should try an AR8

-   ACF : The last value which cross the blue line is Lag=11 so we should try an MR11

```{r}
Arima(uschange[,"Unemployment"],order=c(8,0,0))
```

For AR8 coefficient, absolute value 0.2792 is greater than the standard error 0.0705 so this parameter is significant. However the AIC value is higher than the one found by the automatic guess.

```{r}
Arima(uschange[,"Unemployment"],order=c(0,0,11))
```

For MR11 coefficient, absolute value 0.1847 is greater than the standard error 0.0839 so this parameter is significant.

[3.3 Conclusion : which values are the best ?]{.ul}

Automatic guess shown that the AR2 from automatic guess is better than AR8 from manual guess (best AIC). However MR11 from manual guess is better than MR0 from the automatic guess. So an ARIMA(2,0,11) should be the best model.

```{r}
Arima(uschange[,"Unemployment"],order=c(2,0,11))
```
